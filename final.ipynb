# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

train_data = pd.read_csv('/kaggle/input/hackathon/train.csv')
test_data = pd.read_csv('/kaggle/input/hackathon/test.csv')

# Initialize the label encoder
label_encoder = LabelEncoder()

# Encode the 'label' column and overwrite it
train_data['label'] = label_encoder.fit_transform(train_data['label'])
print(train_data.head())

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Create separate DataFrames for 'mean' and 'var' columns
x_mean = pd.DataFrame()
x_var = pd.DataFrame()
x_mean_test = pd.DataFrame()
x_var_test = pd.DataFrame()

# Extract 'mean' and 'var' columns for spectral_centroid, rolloff, and spectral_bandwidth
x_mean['sp_mean'] = train_data['spectral_centroid_mean']
x_var['sp_var'] = train_data['spectral_centroid_var']
x_mean['ok_mean'] = train_data['rolloff_mean']
x_var['ok_var'] = train_data['rolloff_var']
x_mean['sc_mean'] = train_data['spectral_bandwidth_mean']
x_var['sc_var'] = train_data['spectral_bandwidth_var']
x_mean_test['sp_mean'] = test_data['spectral_centroid_mean']
x_var_test['sp_var'] = test_data['spectral_centroid_var']
x_mean_test['ok_mean'] = test_data['rolloff_mean']
x_var_test['ok_var'] = test_data['rolloff_var']
x_mean_test['sc_mean'] = test_data['spectral_bandwidth_mean']
x_var_test['sc_var'] = test_data['spectral_bandwidth_var']

# Standardize the data
scaler = StandardScaler()
x_mean_scaled = scaler.fit_transform(x_mean)
x_var_scaled = scaler.fit_transform(x_var)
x_mean_test_scaled = scaler.fit_transform(x_mean_test)
x_var_test_scaled = scaler.fit_transform(x_var_test)

# Create PCA instances for 'mean' and 'var'
pca_mean = PCA(n_components=1)
pca_var = PCA(n_components=1)
pca_mean_test = PCA(n_components=1)
pca_var_test = PCA(n_components=1)

# Fit and transform the data using PCA
pca_mean_result = pca_mean.fit_transform(x_mean_scaled)
pca_var_result = pca_var.fit_transform(x_var_scaled)
pca_mean_test_result = pca_mean_test.fit_transform(x_mean_test_scaled)
pca_var_test_result = pca_var_test.fit_transform(x_var_test_scaled)

# Add the PCA results back to the original DataFrame
train_data['pca_mean'] = pca_mean_result
train_data['pca_var'] = pca_var_result
test_data['pca_mean'] = pca_mean_test_result
test_data['pca_var'] = pca_var_test_result

test_id = test_data['id']

import pandas as pd
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
from xgboost import cv
from xgboost import DMatrix
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier

# Drop the variables used to create PCA components
columns_to_drop = ['spectral_centroid_mean', 'spectral_centroid_var', 'rolloff_mean', 'rolloff_var', 'spectral_bandwidth_mean', 'spectral_bandwidth_var']
train_data = train_data.drop(columns=['filename'])
test_data = test_data.drop(columns=['id'])
train_data = train_data.drop(columns=columns_to_drop)
test_data = test_data.drop(columns=columns_to_drop)

# Encode the 'label' column
label_encoder = LabelEncoder()
train_data['label'] = label_encoder.fit_transform(train_data['label'])

# Split the dataset into features (X) and labels (y) for training
X_train = train_data.drop(columns=['label'])
y_train = train_data['label']

# Get the class labels for decoding the confusion matrix
class_labels = label_encoder.classes_

# Standardize the feature values (mean=0, variance=1) for both training and test data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
test_data = scaler.fit_transform(test_data)

# Split the training data into a training set and a validation set
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

X_val = scaler.fit_transform(X_val)

svm_model = SVC(kernel='rbf', C=14, random_state=42, probability=True)
svm_model.fit(X_train, y_train)

# Make predictions on the validation set
y_val_pred = svm_model.predict(X_val)

# Calculate the confusion matrix for the validation set
confusion_matrix_val = confusion_matrix(y_val, y_val_pred)

# Calculate the micro-averaged F1 score for the validation set
f1_score_val_micro = f1_score(y_val, y_val_pred, average='micro')

# Calculate the macro-averaged F1 score for the validation set
f1_score_val_macro = f1_score(y_val, y_val_pred, average='macro')

accuracy_val = accuracy_score(y_val, y_val_pred)

error_val = 1 - accuracy_val

print("Validation Set Metrics:")
print(f"Accuracy on Validation Set - SVM: {accuracy_val * 100:.2f}%")
print(f"Confusion Matrix:")
print(pd.DataFrame(confusion_matrix_val, columns=class_labels, index=class_labels))
print(f"Micro-Averaged F1 Score: {f1_score_val_micro:.2f}")
print(f"Macro-Averaged F1 Score: {f1_score_val_macro:.2f}")
print(f"Misclassification Error: {error_val * 100:.2f}%")

# Make predictions on the training set
y_train_pred = svm_model.predict(X_train)

# Calculate the confusion matrix for the training set
confusion_matrix_train = confusion_matrix(y_train, y_train_pred)

# Calculate the micro-averaged F1 score for the training set
f1_score_train_micro = f1_score(y_train, y_train_pred, average='micro')

# Calculate the macro-averaged F1 score for the training set
f1_score_train_macro = f1_score(y_train, y_train_pred, average='macro')

accuracy_train = accuracy_score(y_train, y_train_pred)

error_train = 1 - accuracy_train

print("\n\n\n")
print("Training Set Metrics:")
print(f"Accuracy on Training Set - SVM: {accuracy_train * 100:.2f}%")
print(f"Confusion Matrix:")
print(pd.DataFrame(confusion_matrix_train, columns=class_labels, index=class_labels))
print(f"Micro-Averaged F1 Score: {f1_score_train_micro:.2f}")
print(f"Macro-Averaged F1 Score: {f1_score_train_macro:.2f}")
print(f"Misclassification Error: {error_train * 100:.2f}%")

# Initialize the Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=40, random_state=42)

# Train the classifier on the training data
rf_classifier.fit(X_train, y_train)

# Make predictions on the training data
y_train_pred = rf_classifier.predict(X_train)

# Make predictions on the validation data
y_val_pred = rf_classifier.predict(X_val)

# Evaluate the model's performance on training and validation data
train_accuracy = accuracy_score(y_train, y_train_pred)
val_accuracy = accuracy_score(y_val, y_val_pred)

'''xgb_classifier = xgb.XGBClassifier(reg_alpha=1.0, reg_lambda=1.0)

xgb_classifier.fit(X_train, y_train)

y_train_pred = xgb_classifier.predict(X_train)
y_pred = xgb_classifier.predict(X_val)

# Specify the number of boosting rounds (num_round)
num_round = 1000

# Define the parameters for your XGBoost model
params = {
    "objective": "multi:softmax",
    "num_class": 10,
    "max_depth": 5,
    "min_child_weight": 1,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "learning_rate": 0.01,
    "reg_alpha": 1.0,  # Increase this value
    "reg_lambda": 1.0,  # Increase this value
}

# Create DMatrix for train and validation data
dtrain = DMatrix(X_train, label=y_train)
dval = DMatrix(X_val, label=y_val)

# Set up early stopping
evals = [(dval, "eval")]
evals_result = {}

# Train the XGBoost model with early stopping
bst = xgb.train(
    params,
    dtrain,
    num_round,
    evals=evals,
    evals_result=evals_result,
    early_stopping_rounds=10,
)

# Make predictions on the validation set
y_pred = bst.predict(dval)
accuracy = accuracy_score(y_val, y_pred)

print(f'Accuracy: {accuracy:.2f}')

test_dmatrix = DMatrix(test_data)
submission = bst.predict(test_dmatrix)'''

estimators = [('rf', rf_classifier), ('svm', svm_model)]
weights = [0.7, 0.3]  # You can adjust the weights accordingly

# Create the weighted ensemble model
ensemble_model = VotingClassifier(estimators=estimators, voting='soft', weights=weights)

# Fit the ensemble model on your training data
ensemble_model.fit(X_train, y_train)

# Make predictions using the ensemble model
y_pred = ensemble_model.predict(X_val)

# Calculate accuracy on the validation set
accuracy = accuracy_score(y_val, y_pred)
print(f'Accuracy - Ensemble: {accuracy:.2f}')

submission = ensemble_model.predict(test_data)
#something = xgb_classifier.predict(test_data)
submission_df = pd.DataFrame({'id':test_id, 'label':submission})
submission_df.to_csv('submission.csv',index=False)
